Search.setIndex({"docnames": ["addstudytodatabase", "addtermstovocab", "authorID", "authors", "generatesubstringmatches", "index", "modules", "newvocabularyuploadchecker", "parentapi", "predictvocabularyterms", "retrievevocabrows", "samples", "studyID", "trainvocabulary", "updateusecount", "validatetermsfortraining"], "filenames": ["addstudytodatabase.rst", "addtermstovocab.rst", "authorID.rst", "authors.rst", "generatesubstringmatches.rst", "index.rst", "modules.rst", "newvocabularyuploadchecker.rst", "parentapi.rst", "predictvocabularyterms.rst", "retrievevocabrows.rst", "samples.rst", "studyID.rst", "trainvocabulary.rst", "updateusecount.rst", "validatetermsfortraining.rst"], "titles": ["addstudytodatabase module", "addtermstovocab module", "authorID module", "authors module", "generatesubstringmatches module", "Welcome to Metadata Standardizer\u2019s documentation!", "code", "newvocabularyuploadchecker module", "parentapi module", "predictvocabularyterms module", "retrievevocabrows module", "samples module", "studyID module", "trainvocabulary module", "updateusecount module", "validatetermsfortraining module"], "terms": {"class": [0, 1, 2, 4, 7, 9, 10, 11, 12, 13, 14, 15], "base": [0, 1, 2, 4, 7, 9, 10, 11, 12, 13, 14, 15], "resourc": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "make_author_id": 0, "make_list_of_dataframes_for_upload": 0, "basic": 0, "idea": 0, "we": [0, 4, 9, 13, 14], "make": [0, 4, 9, 13, 14], "datafram": 0, "method": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "classvar": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "option": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "collect": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "str": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "post": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "The": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "thi": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "view": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "regist": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "us": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "same": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "default": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "get": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "head": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "rout": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "add_url_rul": [0, 1, 2, 4, 9, 10, 11, 12, 13, 14, 15], "take": [0, 1, 4, 10, 13, 14, 15], "set": [0, 1, 4, 10, 13, 14, 15], "word": [0, 1, 4, 10, 13, 14, 15], "add": [0, 1, 4, 10, 13, 14, 15], "them": [0, 1, 4, 10, 13, 14, 15], "vocabulari": [0, 1, 4, 9, 10, 13, 14, 15], "model": [0, 1, 4, 10, 13, 14, 15], "upload_to_databas": 0, "addtermstovocabularyresourc": 1, "append_new_vocab_to_t": 1, "append_to_conglomerate_panda": 1, "read_fil": [1, 4, 9, 13], "validate_vocabulary_request": 1, "write_fil": [1, 14], "coerce_db_into_conglomerate_panda": [4, 9, 13], "origin": [4, 9, 13, 14], "did": [4, 9, 13, 14], "databas": [4, 9, 13, 14], "rather": [4, 9, 13, 14], "just": [4, 9, 13, 14], "larg": [4, 9, 13, 14], "panda": [4, 9, 13, 14], "bin": [4, 9, 13, 14], "hold": [4, 9, 13, 14], "vocab": [4, 9, 13, 14], "info": [4, 9, 13, 14], "were": [4, 9, 13, 14], "motiv": [4, 9, 13, 14], "switch": [4, 9, 13, 14], "db": [4, 9, 13, 14], "order": [4, 9, 13, 14], "ot": [4, 9, 13, 14], "addit": [4, 9, 13, 14], "veri": [4, 9, 13, 14], "fast": [4, 9, 13, 14], "everyth": [4, 9, 13, 14], "wa": [4, 9, 13, 14], "work": [4, 9, 13, 14], "start": [4, 9, 13, 14], "conglomer": [4, 9, 13, 14], "so": [4, 9, 13, 14], "insert": [4, 9, 13, 14], "step": [4, 9, 13, 14], "where": [4, 9, 13, 14], "read": [4, 9, 13, 14], "coerc": [4, 9, 13, 14], "proce": [4, 9, 13, 14], "alreadi": [4, 9, 13, 14], "without": [4, 9, 13, 14], "otuput": [4, 9, 13, 14], "small": [4, 9, 13, 14], "file": [4, 9, 13, 14], "uniqu": [4, 9, 13, 14], "term": [4, 9, 13, 14], "generate_substring_match": 4, "code": 5, "addstudytodatabas": [5, 6], "modul": [5, 6], "addtermstovocab": [5, 6], "authorid": [5, 6], "author": [5, 6], "generatesubstringmatch": [5, 6], "newvocabularyuploadcheck": [5, 6], "parentapi": [5, 6], "predictvocabularyterm": [5, 6], "retrievevocabrow": [5, 6], "sampl": [5, 6], "studyid": [5, 6], "trainvocabulari": [5, 6], "updateusecount": [5, 6], "validatetermsfortrain": [5, 6], "index": 5, "search": 5, "page": 5, "vocabulary_list": 7, "object": 7, "all": 7, "thei": 7, "return": 7, "true": 7, "problem": 7, "check_char_length": 7, "verify_string_abs": 7, "predictvocabularytermsresourc": 9, "append_use_count_properti": 9, "endpoint": [9, 10, 11, 12, 13, 14, 15], "get_neighbor": 9, "mediatyp": [9, 10, 11, 12, 13, 14, 15], "predict": 9, "about": 9, "retrievevocabrowsresourc": 10, "select_row": 10, "trainvocabularyresourc": 13, "train_model": 13, "write_model": 13, "updateusecountresourc": 14, "update_db": 14, "update_use_count": 14, "validatetermsfortrainingresourc": 15, "validate_training_request": 15}, "objects": {"": [[0, 0, 0, "-", "addstudytodatabase"], [1, 0, 0, "-", "addtermstovocab"], [2, 0, 0, "-", "authorID"], [3, 0, 0, "-", "authors"], [4, 0, 0, "-", "generatesubstringmatches"], [7, 0, 0, "-", "newvocabularyuploadchecker"], [8, 0, 0, "-", "parentapi"], [9, 0, 0, "-", "predictvocabularyterms"], [10, 0, 0, "-", "retrievevocabrows"], [11, 0, 0, "-", "samples"], [12, 0, 0, "-", "studyID"], [13, 0, 0, "-", "trainvocabulary"], [14, 0, 0, "-", "updateusecount"], [15, 0, 0, "-", "validatetermsfortraining"]], "addstudytodatabase": [[0, 1, 1, "", "AddStudyToDatabase"]], "addstudytodatabase.AddStudyToDatabase": [[0, 2, 1, "", "make_author_id"], [0, 2, 1, "", "make_list_of_dataframes_for_upload"], [0, 3, 1, "", "methods"], [0, 2, 1, "", "post"], [0, 2, 1, "", "upload_to_database"]], "addtermstovocab": [[1, 1, 1, "", "AddTermsToVocabularyResource"]], "addtermstovocab.AddTermsToVocabularyResource": [[1, 2, 1, "", "append_new_vocab_to_table"], [1, 2, 1, "", "append_to_conglomerate_panda"], [1, 3, 1, "", "methods"], [1, 2, 1, "", "post"], [1, 2, 1, "", "read_files"], [1, 2, 1, "", "validate_vocabulary_request"], [1, 2, 1, "", "write_files"]], "authorID": [[2, 1, 1, "", "AuthorID"]], "authorID.AuthorID": [[2, 3, 1, "", "methods"], [2, 2, 1, "", "post"]], "generatesubstringmatches": [[4, 1, 1, "", "GenerateSubstringMatches"]], "generatesubstringmatches.GenerateSubstringMatches": [[4, 2, 1, "", "coerce_db_into_conglomerate_panda"], [4, 2, 1, "", "generate_substring_matches"], [4, 3, 1, "", "methods"], [4, 2, 1, "", "post"], [4, 2, 1, "", "read_files"]], "newvocabularyuploadchecker": [[7, 1, 1, "", "NewVocabularyUploadChecker"]], "newvocabularyuploadchecker.NewVocabularyUploadChecker": [[7, 2, 1, "", "check_char_length"], [7, 2, 1, "", "verify_string_absence"]], "predictvocabularyterms": [[9, 1, 1, "", "PredictVocabularyTermsResource"]], "predictvocabularyterms.PredictVocabularyTermsResource": [[9, 2, 1, "", "append_use_count_property"], [9, 2, 1, "", "coerce_db_into_conglomerate_panda"], [9, 3, 1, "", "endpoint"], [9, 2, 1, "", "get_neighbors"], [9, 2, 1, "", "mediatypes"], [9, 3, 1, "", "methods"], [9, 2, 1, "", "post"], [9, 2, 1, "", "read_files"]], "retrievevocabrows": [[10, 1, 1, "", "RetrieveVocabRowsResource"]], "retrievevocabrows.RetrieveVocabRowsResource": [[10, 3, 1, "", "endpoint"], [10, 2, 1, "", "mediatypes"], [10, 3, 1, "", "methods"], [10, 2, 1, "", "post"], [10, 2, 1, "", "select_rows"]], "samples": [[11, 1, 1, "", "Samples"]], "samples.Samples": [[11, 3, 1, "", "endpoint"], [11, 2, 1, "", "mediatypes"], [11, 3, 1, "", "methods"], [11, 2, 1, "", "post"]], "studyID": [[12, 1, 1, "", "StudyID"]], "studyID.StudyID": [[12, 3, 1, "", "endpoint"], [12, 2, 1, "", "mediatypes"], [12, 3, 1, "", "methods"], [12, 2, 1, "", "post"]], "trainvocabulary": [[13, 1, 1, "", "TrainVocabularyResource"]], "trainvocabulary.TrainVocabularyResource": [[13, 2, 1, "", "coerce_db_into_conglomerate_panda"], [13, 3, 1, "", "endpoint"], [13, 2, 1, "", "mediatypes"], [13, 3, 1, "", "methods"], [13, 2, 1, "", "post"], [13, 2, 1, "", "read_files"], [13, 2, 1, "", "train_models"], [13, 2, 1, "", "write_models"]], "updateusecount": [[14, 1, 1, "", "UpdateUseCountResource"]], "updateusecount.UpdateUseCountResource": [[14, 3, 1, "", "endpoint"], [14, 2, 1, "", "mediatypes"], [14, 3, 1, "", "methods"], [14, 2, 1, "", "post"], [14, 2, 1, "", "update_db"], [14, 2, 1, "", "update_use_count"], [14, 2, 1, "", "write_file"]], "validatetermsfortraining": [[15, 1, 1, "", "ValidateTermsForTrainingResource"]], "validatetermsfortraining.ValidateTermsForTrainingResource": [[15, 3, 1, "", "endpoint"], [15, 2, 1, "", "mediatypes"], [15, 3, 1, "", "methods"], [15, 2, 1, "", "post"], [15, 2, 1, "", "validate_training_request"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"]}, "titleterms": {"addstudytodatabas": 0, "modul": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15], "addtermstovocab": 1, "authorid": 2, "author": 3, "generatesubstringmatch": 4, "welcom": 5, "metadata": 5, "standard": 5, "s": 5, "document": 5, "content": 5, "indic": 5, "tabl": 5, "code": 6, "newvocabularyuploadcheck": 7, "parentapi": 8, "predictvocabularyterm": 9, "retrievevocabrow": 10, "sampl": 11, "studyid": 12, "trainvocabulari": 13, "updateusecount": 14, "validatetermsfortrain": 15}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx": 56}})